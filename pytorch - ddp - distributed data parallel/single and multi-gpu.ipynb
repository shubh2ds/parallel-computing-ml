{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNQYdJgyxa4P0YZryi8WNzW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Requirements:\n","\n","torch>=1.11.0"],"metadata":{"id":"dj5KPl_1dIxh"}},{"cell_type":"code","source":["!pip install torch>=1.11.0"],"metadata":{"id":"AgjLiKD7egxE","executionInfo":{"status":"ok","timestamp":1740949553149,"user_tz":-330,"elapsed":1915,"user":{"displayName":"Shubham Kumar","userId":"01942334351878641351"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### Single gpu"],"metadata":{"id":"QZ3GkAM5nP6S"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class MyTrainDataset(Dataset):\n","    def __init__(self, size):\n","        self.size = size\n","        self.data = [(torch.rand(20), torch.rand(1)) for _ in range(size)]\n","\n","    def __len__(self):\n","        return self.size\n","\n","    def __getitem__(self, index):\n","        return self.data[index]"],"metadata":{"id":"YLNZi5ihhHhy","executionInfo":{"status":"ok","timestamp":1740949555297,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shubham Kumar","userId":"01942334351878641351"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJbwXUiJcrbd","executionInfo":{"status":"ok","timestamp":1740949559886,"user_tz":-330,"elapsed":383,"user":{"displayName":"Shubham Kumar","userId":"01942334351878641351"}},"outputId":"031a7f08-8320-4a90-a52e-de1d7089cd91"},"outputs":[{"output_type":"stream","name":"stdout","text":["[GPU0] Epoch 0 | Batchsize: 64 | Steps: 32\n","Epoch 0 | Training checkpoint saved at checkpoint.pt\n","[GPU0] Epoch 1 | Batchsize: 64 | Steps: 32\n","[GPU0] Epoch 2 | Batchsize: 64 | Steps: 32\n","Epoch 2 | Training checkpoint saved at checkpoint.pt\n","[GPU0] Epoch 3 | Batchsize: 64 | Steps: 32\n","[GPU0] Epoch 4 | Batchsize: 64 | Steps: 32\n","Epoch 4 | Training checkpoint saved at checkpoint.pt\n","[GPU0] Epoch 5 | Batchsize: 64 | Steps: 32\n","[GPU0] Epoch 6 | Batchsize: 64 | Steps: 32\n","Epoch 6 | Training checkpoint saved at checkpoint.pt\n","[GPU0] Epoch 7 | Batchsize: 64 | Steps: 32\n","[GPU0] Epoch 8 | Batchsize: 64 | Steps: 32\n","Epoch 8 | Training checkpoint saved at checkpoint.pt\n","[GPU0] Epoch 9 | Batchsize: 64 | Steps: 32\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","#from datautils import MyTrainDataset\n","\n","\n","class Trainer:\n","    def __init__(\n","        self,\n","        model: torch.nn.Module,\n","        train_data: DataLoader,\n","        optimizer: torch.optim.Optimizer,\n","        gpu_id: int,\n","        save_every: int,\n","    ) -> None:\n","        self.gpu_id = gpu_id\n","        self.model = model.to(gpu_id)\n","        self.train_data = train_data\n","        self.optimizer = optimizer\n","        self.save_every = save_every\n","\n","    def _run_batch(self, source, targets):\n","        self.optimizer.zero_grad()\n","        output = self.model(source)\n","        loss = F.cross_entropy(output, targets)\n","        loss.backward()\n","        self.optimizer.step()\n","\n","    def _run_epoch(self, epoch):\n","        b_sz = len(next(iter(self.train_data))[0])\n","        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n","        for source, targets in self.train_data:\n","            source = source.to(self.gpu_id)\n","            targets = targets.to(self.gpu_id)\n","            self._run_batch(source, targets)\n","\n","    def _save_checkpoint(self, epoch):\n","        ckp = self.model.state_dict()\n","        PATH = \"checkpoint.pt\"\n","        torch.save(ckp, PATH)\n","        print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n","\n","    def train(self, max_epochs: int):\n","        for epoch in range(max_epochs):\n","            self._run_epoch(epoch)\n","            if epoch % self.save_every == 0:\n","                self._save_checkpoint(epoch)\n","\n","\n","def load_train_objs():\n","    train_set = MyTrainDataset(2048)  # load your dataset\n","    model = torch.nn.Linear(20, 1)  # load your model\n","    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","    return train_set, model, optimizer\n","\n","\n","def prepare_dataloader(dataset: Dataset, batch_size: int):\n","    return DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        pin_memory=True,\n","        shuffle=True\n","    )\n","\n","\n","def main(device, total_epochs, save_every, batch_size):\n","    dataset, model, optimizer = load_train_objs()\n","    train_data = prepare_dataloader(dataset, batch_size)\n","    trainer = Trainer(model, train_data, optimizer, device, save_every)\n","    trainer.train(total_epochs)\n","\n","\n","if __name__ == \"__main__\":\n","    \"\"\"import argparse\n","    parser = argparse.ArgumentParser(description='simple distributed training job')\n","    parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')\n","    parser.add_argument('save_every', type=int, help='How often to save a snapshot')\n","    parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')\n","    args = parser.parse_args()\n","\n","    device = 0  # shorthand for cuda:0\n","    main(device, args.total_epochs, args.save_every, args.batch_size)\"\"\"\n","\n","    main(device = 0, total_epochs=10, save_every=2, batch_size=64)"]},{"cell_type":"markdown","source":["### Multi-gpu"],"metadata":{"id":"K-oamCg2nV_e"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","#from datautils import MyTrainDataset\n","\n","import torch.multiprocessing as mp\n","from torch.utils.data.distributed import DistributedSampler\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","from torch.distributed import init_process_group, destroy_process_group\n","import os\n","\n","\n","def ddp_setup(rank, world_size):\n","    \"\"\"\n","    Args:\n","        rank: Unique identifier of each process\n","        world_size: Total number of processes\n","    \"\"\"\n","    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n","    os.environ[\"MASTER_PORT\"] = \"12355\"\n","    torch.cuda.set_device(rank)\n","    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n","\n","class Trainer:\n","    def __init__(\n","        self,\n","        model: torch.nn.Module,\n","        train_data: DataLoader,\n","        optimizer: torch.optim.Optimizer,\n","        gpu_id: int,\n","        save_every: int,\n","    ) -> None:\n","        self.gpu_id = gpu_id\n","        self.model = model.to(gpu_id)\n","        self.train_data = train_data\n","        self.optimizer = optimizer\n","        self.save_every = save_every\n","        self.model = DDP(model, device_ids=[gpu_id])\n","\n","    def _run_batch(self, source, targets):\n","        self.optimizer.zero_grad()\n","        output = self.model(source)\n","        loss = F.cross_entropy(output, targets)\n","        loss.backward()\n","        self.optimizer.step()\n","\n","    def _run_epoch(self, epoch):\n","        b_sz = len(next(iter(self.train_data))[0])\n","        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n","        self.train_data.sampler.set_epoch(epoch)\n","        for source, targets in self.train_data:\n","            source = source.to(self.gpu_id)\n","            targets = targets.to(self.gpu_id)\n","            self._run_batch(source, targets)\n","\n","    def _save_checkpoint(self, epoch):\n","        ckp = self.model.module.state_dict()\n","        PATH = \"checkpoint.pt\"\n","        torch.save(ckp, PATH)\n","        print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n","\n","    def train(self, max_epochs: int):\n","        for epoch in range(max_epochs):\n","            self._run_epoch(epoch)\n","            if self.gpu_id == 0 and epoch % self.save_every == 0:\n","                self._save_checkpoint(epoch)\n","\n","\n","def load_train_objs():\n","    train_set = MyTrainDataset(2048)  # load your dataset\n","    model = torch.nn.Linear(20, 1)  # load your model\n","    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","    return train_set, model, optimizer\n","\n","\n","def prepare_dataloader(dataset: Dataset, batch_size: int):\n","    return DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        pin_memory=True,\n","        shuffle=False,\n","        sampler=DistributedSampler(dataset)\n","    )\n","\n","\n","def main(rank: int, world_size: int, save_every: int, total_epochs: int, batch_size: int):\n","    ddp_setup(rank, world_size)\n","    dataset, model, optimizer = load_train_objs()\n","    train_data = prepare_dataloader(dataset, batch_size)\n","    trainer = Trainer(model, train_data, optimizer, rank, save_every)\n","    trainer.train(total_epochs)\n","    destroy_process_group()\n","\n","\n","if __name__ == \"__main__\":\n","    \"\"\"import argparse\n","    parser = argparse.ArgumentParser(description='simple distributed training job')\n","    parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')\n","    parser.add_argument('save_every', type=int, help='How often to save a snapshot')\n","    parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')\n","    args = parser.parse_args()\n","\n","    world_size = torch.cuda.device_count()\n","    mp.spawn(main, args=(world_size, args.save_every, args.total_epochs, args.batch_size), nprocs=world_size)\"\"\"\n","\n","    world_size = torch.cuda.device_count()\n","    mp.spawn(main, args=(world_size, 2, 10, 64), nprocs=world_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"eO6d8tTedPNY","executionInfo":{"status":"error","timestamp":1740949645269,"user_tz":-330,"elapsed":1864,"user":{"displayName":"Shubham Kumar","userId":"01942334351878641351"}},"outputId":"5891bf70-9ed4-4ff5-ca75-0e60646ea346"},"execution_count":21,"outputs":[{"output_type":"error","ename":"ProcessExitedException","evalue":"process 0 terminated with exit code 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-b6c9bbcad686>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mworld_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    326\u001b[0m         )\n\u001b[1;32m    327\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spawn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 )\n\u001b[1;32m    191\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 raise ProcessExitedException(\n\u001b[0m\u001b[1;32m    193\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0merror_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"]}]},{"cell_type":"markdown","source":["### multi-gpu torch run"],"metadata":{"id":"jg5KzgLlsKdy"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class MyTrainDataset(Dataset):\n","    def __init__(self, size):\n","        self.size = size\n","        self.data = [(torch.rand(20), torch.rand(1)) for _ in range(size)]\n","\n","    def __len__(self):\n","        return self.size\n","\n","    def __getitem__(self, index):\n","        return self.data[index]"],"metadata":{"id":"E6Qibd7Ostjr","executionInfo":{"status":"ok","timestamp":1740949892000,"user_tz":-330,"elapsed":37,"user":{"displayName":"Shubham Kumar","userId":"01942334351878641351"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","#from datautils import MyTrainDataset\n","\n","import torch.multiprocessing as mp\n","from torch.utils.data.distributed import DistributedSampler\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","from torch.distributed import init_process_group, destroy_process_group\n","import os\n","\n","\n","def ddp_setup():\n","    world_size = torch.cuda.device_count()\n","    torch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n","    init_process_group(backend=\"nccl\")\n","\n","class Trainer:\n","    def __init__(\n","        self,\n","        model: torch.nn.Module,\n","        train_data: DataLoader,\n","        optimizer: torch.optim.Optimizer,\n","        save_every: int,\n","        snapshot_path: str,\n","    ) -> None:\n","        self.gpu_id = int(os.environ[\"LOCAL_RANK\"])\n","        self.model = model.to(self.gpu_id)\n","        self.train_data = train_data\n","        self.optimizer = optimizer\n","        self.save_every = save_every\n","        self.epochs_run = 0\n","        self.snapshot_path = snapshot_path\n","        if os.path.exists(snapshot_path):\n","            print(\"Loading snapshot\")\n","            self._load_snapshot(snapshot_path)\n","\n","        self.model = DDP(self.model, device_ids=[self.gpu_id])\n","\n","    def _load_snapshot(self, snapshot_path):\n","        loc = f\"cuda:{self.gpu_id}\"\n","        snapshot = torch.load(snapshot_path, map_location=loc)\n","        self.model.load_state_dict(snapshot[\"MODEL_STATE\"])\n","        self.epochs_run = snapshot[\"EPOCHS_RUN\"]\n","        print(f\"Resuming training from snapshot at Epoch {self.epochs_run}\")\n","\n","    def _run_batch(self, source, targets):\n","        self.optimizer.zero_grad()\n","        output = self.model(source)\n","        loss = F.cross_entropy(output, targets)\n","        loss.backward()\n","        self.optimizer.step()\n","\n","    def _run_epoch(self, epoch):\n","        b_sz = len(next(iter(self.train_data))[0])\n","        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n","        self.train_data.sampler.set_epoch(epoch)\n","        for source, targets in self.train_data:\n","            source = source.to(self.gpu_id)\n","            targets = targets.to(self.gpu_id)\n","            self._run_batch(source, targets)\n","\n","    def _save_snapshot(self, epoch):\n","        snapshot = {\n","            \"MODEL_STATE\": self.model.module.state_dict(),\n","            \"EPOCHS_RUN\": epoch,\n","        }\n","        torch.save(snapshot, self.snapshot_path)\n","        print(f\"Epoch {epoch} | Training snapshot saved at {self.snapshot_path}\")\n","\n","    def train(self, max_epochs: int):\n","        for epoch in range(self.epochs_run, max_epochs):\n","            self._run_epoch(epoch)\n","            if self.gpu_id == 0 and epoch % self.save_every == 0:\n","                self._save_snapshot(epoch)\n","\n","\n","def load_train_objs():\n","    train_set = MyTrainDataset(2048)  # load your dataset\n","    model = torch.nn.Linear(20, 1)  # load your model\n","    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","    return train_set, model, optimizer\n","\n","\n","def prepare_dataloader(dataset: Dataset, batch_size: int):\n","    return DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        pin_memory=True,\n","        shuffle=False,\n","        sampler=DistributedSampler(dataset)\n","    )\n","\n","\n","def main(save_every: int, total_epochs: int, batch_size: int, snapshot_path: str = \"snapshot.pt\"):\n","    ddp_setup()\n","    dataset, model, optimizer = load_train_objs()\n","    train_data = prepare_dataloader(dataset, batch_size)\n","    trainer = Trainer(model, train_data, optimizer, save_every, snapshot_path)\n","    trainer.train(total_epochs)\n","    destroy_process_group()\n","\n","\n","if __name__ == \"__main__\":\n","    \"\"\"import argparse\n","    parser = argparse.ArgumentParser(description='simple distributed training job')\n","    parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')\n","    parser.add_argument('save_every', type=int, help='How often to save a snapshot')\n","    parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')\n","    args = parser.parse_args()\n","    main(args.save_every, args.total_epochs, args.batch_size)\n","    \"\"\"\n","    main(total_epochs=10, save_every=2, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"XyEAW3uFsN6U","executionInfo":{"status":"error","timestamp":1740950146790,"user_tz":-330,"elapsed":57,"user":{"displayName":"Shubham Kumar","userId":"01942334351878641351"}},"outputId":"9284ff8b-10eb-4470-8238-98a9c7b1e56b"},"execution_count":27,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'LOCAL_RANK'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-b5fee960eaaa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-b5fee960eaaa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(save_every, total_epochs, batch_size, snapshot_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_every\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"snapshot.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mddp_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_train_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-b5fee960eaaa>\u001b[0m in \u001b[0;36mddp_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mddp_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mworld_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LOCAL_RANK\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0minit_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nccl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'LOCAL_RANK'"]}]}]}