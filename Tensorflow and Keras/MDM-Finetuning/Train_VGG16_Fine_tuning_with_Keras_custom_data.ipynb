{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj8SyR7-kq_D"
      },
      "source": [
        "l=[]\n",
        "while(1):\n",
        "  l.append(\"1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQONxTeZkvGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ac48412-d3ea-4766-d241-f9b99e64953e"
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.9.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.0.1\n",
            "asgiref==3.2.3\n",
            "astor==0.8.1\n",
            "astropy==4.0\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.3.0\n",
            "attrs==19.3.0\n",
            "audioread==2.1.8\n",
            "autograd==1.3\n",
            "Babel==2.8.0\n",
            "backcall==0.1.0\n",
            "backports.tempfile==1.0\n",
            "backports.weakref==1.0.post1\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.1.0\n",
            "blis==0.2.4\n",
            "bokeh==1.4.0\n",
            "boto==2.49.0\n",
            "boto3==1.11.15\n",
            "botocore==1.14.15\n",
            "Bottleneck==1.3.1\n",
            "branca==0.3.1\n",
            "bs4==0.0.1\n",
            "bz2file==0.98\n",
            "cachetools==3.1.1\n",
            "certifi==2019.11.28\n",
            "cffi==1.14.0\n",
            "chainer==6.5.0\n",
            "chardet==3.0.4\n",
            "chart-studio==1.0.0\n",
            "Click==7.0\n",
            "cloudpickle==1.2.2\n",
            "cmake==3.12.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.2.0\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.0\n",
            "cupy-cuda101==6.5.0\n",
            "cvxopt==1.2.4\n",
            "cvxpy==1.0.25\n",
            "cycler==0.10.0\n",
            "cymem==2.0.3\n",
            "Cython==0.29.15\n",
            "daft==0.0.4\n",
            "dask==2.9.2\n",
            "dataclasses==0.7\n",
            "datascience==0.10.6\n",
            "decorator==4.4.1\n",
            "defusedxml==0.6.0\n",
            "descartes==1.1.0\n",
            "dill==0.3.1.1\n",
            "distributed==1.25.3\n",
            "Django==3.0.3\n",
            "dlib==19.18.0\n",
            "dm-sonnet==1.35\n",
            "docopt==0.6.2\n",
            "docutils==0.15.2\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.213\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.1.0\n",
            "entrypoints==0.3\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.60\n",
            "fastdtw==0.3.4\n",
            "fastprogress==0.2.2\n",
            "fastrlock==0.4\n",
            "fbprophet==0.5\n",
            "feather-format==0.4.0\n",
            "featuretools==0.4.1\n",
            "filelock==3.0.12\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.1\n",
            "folium==0.8.3\n",
            "fsspec==0.6.2\n",
            "future==0.16.0\n",
            "gast==0.2.2\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gevent==1.4.0\n",
            "gin-config==0.3.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.16.0\n",
            "google-api-python-client==1.7.11\n",
            "google-auth==1.7.2\n",
            "google-auth-httplib2==0.0.3\n",
            "google-auth-oauthlib==0.4.1\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.16.2\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.1.8\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.51.0\n",
            "googledrivedownloader==0.4\n",
            "graph-nets==1.0.5\n",
            "graphviz==0.10.1\n",
            "greenlet==0.4.15\n",
            "grpcio==1.27.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.4\n",
            "gunicorn==20.0.4\n",
            "gym==0.15.6\n",
            "h5py==2.8.0\n",
            "HeapDict==1.0.1\n",
            "holidays==0.9.12\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.11.3\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.8\n",
            "image==1.5.28\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==1.5.0\n",
            "imutils==0.5.3\n",
            "inflect==2.1.0\n",
            "intel-openmp==2020.0.133\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.6.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.5.1\n",
            "itsdangerous==1.1.0\n",
            "jax==0.1.58\n",
            "jaxlib==0.1.38\n",
            "jdcal==1.4.1\n",
            "jedi==0.16.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.1\n",
            "jmespath==0.9.4\n",
            "joblib==0.14.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.4\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.6.2\n",
            "kaggle==1.5.6\n",
            "kapre==0.1.3.1\n",
            "Keras==2.2.5\n",
            "Keras-Applications==1.0.8\n",
            "Keras-Preprocessing==1.1.0\n",
            "keras-vis==0.4.1\n",
            "kfac==0.2.0\n",
            "kiwisolver==1.1.0\n",
            "knnimpute==0.1.0\n",
            "librosa==0.6.3\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.31.0\n",
            "lmdb==0.98\n",
            "lucid==0.3.8\n",
            "lunardate==0.2.0\n",
            "lxml==4.2.6\n",
            "magenta==0.3.19\n",
            "Markdown==3.2.1\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.1.3\n",
            "matplotlib-venn==0.11.5\n",
            "mesh-tensorflow==0.1.9\n",
            "mido==1.2.6\n",
            "mir-eval==0.5\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.2.0\n",
            "moviepy==0.2.3.5\n",
            "mpi4py==3.0.3\n",
            "mpmath==1.1.0\n",
            "msgpack==0.5.6\n",
            "multiprocess==0.70.9\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.2\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.0.4\n",
            "networkx==2.4\n",
            "nibabel==2.3.3\n",
            "nltk==3.2.5\n",
            "notebook==5.2.2\n",
            "np-utils==0.5.12.1\n",
            "numba==0.47.0\n",
            "numexpr==2.7.1\n",
            "numpy==1.17.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.1.0\n",
            "osqp==0.6.1\n",
            "packaging==20.1\n",
            "palettable==3.3.0\n",
            "pandas==0.25.3\n",
            "pandas-datareader==0.7.4\n",
            "pandas-gbq==0.11.0\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.2\n",
            "parso==0.6.1\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==6.2.2\n",
            "pip-tools==4.2.0\n",
            "plac==0.9.6\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "portpicker==1.3.1\n",
            "prefetch-generator==1.0.1\n",
            "preshed==2.0.1\n",
            "pretty-midi==0.2.8\n",
            "prettytable==0.7.2\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.7.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.10.0\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.6.0\n",
            "py==1.8.1\n",
            "pyarrow==0.14.1\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.0\n",
            "pycparser==2.19\n",
            "pydata-google-auth==0.3.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyglet==1.4.10\n",
            "Pygments==2.1.3\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "PyMeeus==0.3.6\n",
            "pymongo==3.10.1\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.6\n",
            "pypng==0.0.20\n",
            "pyrsistent==0.15.7\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==1.6.5+ubuntu0.2\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.6.1\n",
            "python-louvain==0.13\n",
            "python-rtmidi==1.4.0\n",
            "python-slugify==4.0.0\n",
            "python-utils==2.3.0\n",
            "pytz==2018.9\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==17.0.0\n",
            "qtconsole==4.6.0\n",
            "regex==2019.12.20\n",
            "requests==2.21.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==2.9.5\n",
            "rsa==4.0\n",
            "s3fs==0.4.0\n",
            "s3transfer==0.3.3\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.1.post2\n",
            "seaborn==0.10.0\n",
            "semantic-version==2.8.4\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.0\n",
            "simplegeneric==0.8.1\n",
            "six==1.12.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==1.9.0\n",
            "snowballstemmer==2.0.0\n",
            "sortedcontainers==2.1.0\n",
            "spacy==2.1.9\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-websupport==1.2.0\n",
            "SQLAlchemy==1.3.13\n",
            "sqlparse==0.3.0\n",
            "srsly==1.0.1\n",
            "stable-baselines==2.2.1\n",
            "statsmodels==0.10.2\n",
            "sympy==1.1.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.6\n",
            "tblib==1.6.0\n",
            "tensor2tensor==1.14.1\n",
            "tensorboard==1.15.0\n",
            "tensorboardcolab==0.0.22\n",
            "tensorflow==1.15.0\n",
            "tensorflow-datasets==2.0.0\n",
            "tensorflow-estimator==1.15.1\n",
            "tensorflow-gan==2.0.0\n",
            "tensorflow-hub==0.7.0\n",
            "tensorflow-metadata==0.21.1\n",
            "tensorflow-privacy==0.2.2\n",
            "tensorflow-probability==0.7.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.8.3\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "tflearn==0.3.2\n",
            "Theano==1.0.4\n",
            "thinc==7.0.8\n",
            "toolz==0.10.0\n",
            "torch==1.4.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.5.0\n",
            "tornado==4.5.3\n",
            "tqdm==4.28.1\n",
            "traitlets==4.3.3\n",
            "tweepy==3.6.0\n",
            "typing==3.6.6\n",
            "typing-extensions==3.6.6\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.3.10\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.8.0\n",
            "wasabi==0.6.0\n",
            "wcwidth==0.1.8\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.0\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.11.2\n",
            "xarray==0.14.1\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==1.0.0\n",
            "zipp==3.0.0\n",
            "zmq==0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDUqICsEv6xG",
        "outputId": "eb323fe0-11c7-4979-8787-a41cd5da8faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9_stTazddg"
      },
      "source": [
        "https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96tOiahpm0-A"
      },
      "source": [
        "The dataset consists of 16,643 images belonging to 11 major food categories:\n",
        "Bread (1724 images)\n",
        "Dairy product (721 images)\n",
        "Dessert (2,500 images)\n",
        "Egg (1,648 images)\n",
        "Fried food (1,461images)\n",
        "Meat (2,206 images)\n",
        "Noodles/pasta (734 images)\n",
        "Rice (472 images)\n",
        "Seafood (1,505 images)\n",
        "Soup (2,500 images)\n",
        "Vegetable/fruit (1,172 images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2YKru-tl4WL"
      },
      "source": [
        "!wget --passive-ftp --prefer-family=ipv4 --ftp-user FoodImage@grebvm2.epfl.ch \\\n",
        "\t--ftp-password Cahc1moo ftp://tremplin.epfl.ch/Food-11.zip\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSoMoG8jnbvr"
      },
      "source": [
        "$ tree --dirsfirst --filelimit 10\n",
        "\n",
        "├── Food-11\n",
        "│   ├── evaluation [3347 entries]\n",
        "│   ├── training [9866 entries]\n",
        "│   ├── validation [3430 entries]\n",
        "│   └── Food-11.zip\n",
        "\n",
        "├── dataset\n",
        "\n",
        "├── output\n",
        "│   ├── unfrozen.png\n",
        "│   └── warmup.png\n",
        "\n",
        "├── pyimagesearch\n",
        "│   ├── __init__.py\n",
        "│   └── config.py\n",
        "\n",
        "├── build_dataset.py\n",
        "\n",
        "├── predict.py\n",
        "\n",
        "└── train.py\n",
        "\n",
        "7 directories, 8 files\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXYFgxj8oap1"
      },
      "source": [
        "#Config.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djSNbXKWoZrX"
      },
      "source": [
        "# import the necessary packages\n",
        "#import os\n",
        "\n",
        "# initialize the path to the *original* input directory of images\n",
        "#ORIG_INPUT_DATASET = \"Food-11\"\n",
        "\n",
        "# initialize the base path to the *new* directory that will contain\n",
        "# our images after computing the training and testing split\n",
        "#BASE_PATH = \"dataset\"\n",
        "\n",
        "# define the names of the training, testing, and validation\n",
        "# directories\n",
        "#TRAIN = \"training\"\n",
        "#TEST = \"evaluation\"\n",
        "#VAL = \"validation\"\n",
        "\n",
        "TRAIN_Dir = \"/content/drive/My Drive/Data/MDM/train\"\n",
        "TEST_Dir = \"/content/drive/My Drive/Data/MDM/test\"\n",
        "VAL_Dir = \"/content/drive/My Drive/Data/MDM/test\"\n",
        "\n",
        "# initialize the list of class label names\n",
        "\"\"\"\n",
        "CLASSES = [\"Bread\", \"Dairy product\", \"Dessert\", \"Egg\", \"Fried food\",\n",
        "\t\"Meat\", \"Noodles/Pasta\", \"Rice\", \"Seafood\", \"Soup\",\n",
        "\t\"Vegetable/Fruit\"]\n",
        "\"\"\"\n",
        "#CLASSES=['Boondi Raita', 'Boiled Egg', 'Chana Lauki Dal', 'Bhindi', 'Banana', 'Chai', 'Chana Dal', 'Chana Dal Chawal', 'Boiled Plain Rice', 'Besan Kadi', 'Kadi Chawal', 'Chole', 'Kheera Salad', 'Dahi', 'Khichi Urad Dal', 'Dal Palak', 'Kale Chane', 'Kheera Raita', 'Chole Chawal', 'Khichdi Moong Dal', 'Rajma', 'Patta Gobi', 'Lauki', 'Moong Masoor Ki Dal', 'Mooli Ki Sabzi', 'Milk', 'Lobia Dal', 'Lassi', 'Masoor Dal', 'Orange', 'Urad Ki Dal', 'Aloo Gobhi', 'Aloo Gajar Mutter', 'Roti', 'Saag', 'Ramdana', 'Rajma Chawal', 'Water', 'Aloo Baingan', 'Aloo Methi', 'Aloo Mutter', 'Aloo Nutri', 'Amrood', 'Aloo Shimla Mirch', 'Aloo Sabzi', 'Apple']\n",
        "CLASSES=['Aloo Baingan','Aloo Gajar Mutter','Aloo Gobhi','Aloo Methi','Aloo Mutter','Aloo Nutri','Aloo Sabzi','Aloo Shimla Mirch','Amrood','Apple','Banana','Besan Kadi','Bhindi','Boiled Egg','Boiled Plain Rice','Boondi Raita','Chai','Chana Dal','Chana Dal Chawal','Chana Lauki Dal','Chole','Chole Chawal','Dahi','Dal Palak','Kadi Chawal','Kale Chane','Kheera Raita','Kheera Salad','Khichdi Moong Dal','Khichi Urad Dal','Lassi','Lauki','Lobia Dal','Masoor Dal','Milk','Mooli Ki Sabzi','Moong Masoor Ki Dal','Orange','Patta Gobi','Rajma','Rajma Chawal','Ramdana','Roti','Saag','Urad Ki Dal','Water']\n",
        "\n",
        "\n",
        "# set the batch size when fine-tuning\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# initialize the label encoder file path and the output directory to\n",
        "# where the extracted features (in CSV file format) will be stored\n",
        "LE_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/le.cpickle\"\n",
        "#LE_PATH = os.path.sep.join([\"output\", \"le.cpickle\"])\n",
        "#BASE_CSV_PATH = \"output\"\n",
        "BASE_CSV_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output\"\n",
        "\n",
        "# set the path to the serialized model after training\n",
        "#MODEL_PATH = os.path.sep.join([\"output\", \"food11.model\"])\n",
        "MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/MDM_46.model\"\n",
        "#NetHead1_19_20_MODEL_PATH ---> NetHead_MODEL_PATH\n",
        "NetHead_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetHead.h5\"\n",
        "NetHead1_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetHead1.h5\"\n",
        "NetHead19_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetHead19.h5\"\n",
        "\n",
        "NetComplete_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetComplete.h5\"\n",
        "NetComplete19_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetComplete19.h5\"\n",
        "\n",
        "# define the path to the output training history plots\n",
        "#UNFROZEN_PLOT_PATH = os.path.sep.join([\"output\", \"unfrozen.png\"])\n",
        "UNFROZEN_PLOT_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/unfrozen.png\"\n",
        "#WARMUP_PLOT_PATH = os.path.sep.join([\"output\", \"warmup.png\"])\n",
        "WARMUP_PLOT_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/warmup.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAKI5qpPwS-L",
        "outputId": "98e1f94f-ed3d-4d45-a50a-632791f6c900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "classs_list=[]\n",
        "for x in os.listdir(TRAIN_Dir):\n",
        "    classs_list.append(x)\n",
        "print(classs_list)\n",
        "print(len(classs_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Boondi Raita', 'Boiled Egg', 'Chana Lauki Dal', 'Bhindi', 'Banana', 'Chai', 'Chana Dal', 'Chana Dal Chawal', 'Boiled Plain Rice', 'Besan Kadi', 'Kadi Chawal', 'Chole', 'Kheera Salad', 'Dahi', 'Khichi Urad Dal', 'Dal Palak', 'Kale Chane', 'Kheera Raita', 'Chole Chawal', 'Khichdi Moong Dal', 'Rajma', 'Patta Gobi', 'Lauki', 'Moong Masoor Ki Dal', 'Mooli Ki Sabzi', 'Milk', 'Lobia Dal', 'Lassi', 'Masoor Dal', 'Orange', 'Urad Ki Dal', 'Aloo Gobhi', 'Aloo Gajar Mutter', 'Roti', 'Saag', 'Ramdana', 'Rajma Chawal', 'Water', 'Aloo Baingan', 'Aloo Methi', 'Aloo Mutter', 'Aloo Nutri', 'Amrood', 'Aloo Shimla Mirch', 'Aloo Sabzi', 'Apple']\n",
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ak8-hjDo_24"
      },
      "source": [
        "#Build_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzr-WSpf8tUy"
      },
      "source": [
        "# USAGE\n",
        "# python build_dataset.py\n",
        "\n",
        "# import the necessary packages\n",
        "#from pyimagesearch import config\n",
        "from imutils import paths\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# loop over the data splits\n",
        "for split in (config.TRAIN, config.TEST, config.VAL):\n",
        "\t# grab all image paths in the current split\n",
        "\tprint(\"[INFO] processing '{} split'...\".format(split))\n",
        "\tp = os.path.sep.join([config.ORIG_INPUT_DATASET, split])\n",
        "\timagePaths = list(paths.list_images(p))\n",
        "\n",
        "\t# loop over the image paths\n",
        "\tfor imagePath in imagePaths:\n",
        "\t\t# extract class label from the filename\n",
        "\t\tfilename = imagePath.split(os.path.sep)[-1]\n",
        "\t\tlabel = config.CLASSES[int(filename.split(\"_\")[0])]\n",
        "\n",
        "\t\t# construct the path to the output directory\n",
        "\t\tdirPath = os.path.sep.join([config.BASE_PATH, split, label])\n",
        "\n",
        "\t\t# if the output directory does not exist, create it\n",
        "\t\tif not os.path.exists(dirPath):\n",
        "\t\t\tos.makedirs(dirPath)\n",
        "\n",
        "\t\t# construct the path to the output image file and copy it\n",
        "\t\tp = os.path.sep.join([dirPath, filename])\n",
        "\t\tshutil.copy2(imagePath, p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IurS_wUod_-"
      },
      "source": [
        "#Train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6yriwFqqIuo",
        "outputId": "485f9e83-7334-4545-8b86-a05d1b788316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# USAGE\n",
        "# python train.py\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import classification_report\n",
        "#from pyimagesearch import config\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlrrBpznqehV"
      },
      "source": [
        "\n",
        "def plot_training(H, N, plotPath):\n",
        "\t# construct a plot that plots and saves the training history\n",
        "\tplt.style.use(\"ggplot\")\n",
        "\tplt.figure()\n",
        "\tplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "\tplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "\tplt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "\tplt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "\tplt.title(\"Training Loss and Accuracy\")\n",
        "\tplt.xlabel(\"Epoch #\")\n",
        "\tplt.ylabel(\"Loss/Accuracy\")\n",
        "\tplt.legend(loc=\"lower left\")\n",
        "\tplt.savefig(plotPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWF-arzmt2Lz",
        "outputId": "ae4f18e5-0133-4515-c09d-bfa8c353f11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# derive the paths to the training, validation, and testing\n",
        "# directories\n",
        "\"\"\"\n",
        "trainPath = os.path.sep.join([config.BASE_PATH, config.TRAIN])\n",
        "valPath = os.path.sep.join([config.BASE_PATH, config.VAL])\n",
        "testPath = os.path.sep.join([config.BASE_PATH, config.TEST])\n",
        "\"\"\"\n",
        "trainPath = TRAIN_Dir\n",
        "valPath = TEST_Dir\n",
        "testPath = TEST_Dir\n",
        "\n",
        "# determine the total number of image paths in training, validation,\n",
        "# and testing directories\n",
        "totalTrain = len(list(paths.list_images(trainPath)))\n",
        "totalVal = len(list(paths.list_images(valPath)))\n",
        "totalTest = len(list(paths.list_images(testPath)))\n",
        "print(\"totalTrain:\",totalTrain)\n",
        "print(\"totalVal:\",totalVal)\n",
        "print(\"totalTest:\",totalTest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "totalTrain: 32583\n",
            "totalVal: 8077\n",
            "totalTest: 8077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxuwc3CmuTVk"
      },
      "source": [
        "\n",
        "# initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "valAug = ImageDataGenerator()\n",
        "\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7uWez22vSVY",
        "outputId": "a79f61cf-2bde-4d3b-93ae-05e46185d298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# initialize the training generator\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\ttrainPath,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "\n",
        "# initialize the validation generator\n",
        "valGen = valAug.flow_from_directory(\n",
        "\tvalPath,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "\n",
        "# initialize the testing generator\n",
        "testGen = valAug.flow_from_directory(\n",
        "\ttestPath,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 32583 images belonging to 46 classes.\n",
            "Found 8077 images belonging to 46 classes.\n",
            "Found 8077 images belonging to 46 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9syccNp8B28"
      },
      "source": [
        "#==========Train1======================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFB1X1E2xnaK",
        "outputId": "9fcef3e4-2aa4-4eb3-a28e-913086916017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# load the VGG16 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(len(CLASSES), activation=\"softmax\")(headModel)\n",
        "\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAsRIvQ1yBEL",
        "outputId": "173f5f6e-890f-4a62-81f5-3d8fbda5e8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "# loop over the layers in the model and show which ones are trainable\n",
        "# or not\n",
        "for layer in model.layers:\n",
        "\tprint(\"{}: {}\".format(layer, layer.trainable))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f8c8bf01588>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8bf01780>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8bf01f60>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f8c8bf0fbe0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8aaa79e8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a848b70>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f8c8a84b860>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a857898>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a857eb8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a7e2518>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f8c8a7e5780>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a7f27b8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a7f2cc0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a7f5e48>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f8c8a801668>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a807e80>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a80beb8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f8c8a811da0>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f8c8a81b5c0>: False\n",
            "<keras.layers.core.Flatten object at 0x7f8c8a7a5eb8>: True\n",
            "<keras.layers.core.Dense object at 0x7f8c8a7aee10>: True\n",
            "<keras.layers.core.Dropout object at 0x7f8c8a77cfd0>: True\n",
            "<keras.layers.core.Dense object at 0x7f8c8a77cba8>: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI9tJ8aSyYn-",
        "outputId": "b6280568-79b4-4601-bcc0-a9bd985fdcfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "# compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network for a few epochs (all other layers\n",
        "# are frozen) -- this will allow the new FC layers to start to become\n",
        "# initialized with actual \"learned\" values versus pure random\n",
        "print(\"[INFO] training head...\")\n",
        "import keras\n",
        "modelpath =NetHead_MODEL_PATH #\"/content/drive/My Drive/Data/MDM/vgg16_46labels1.h5\"NetHead_MODEL_PATH\n",
        "sv_callback = keras.callbacks.ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto',period=1)\n",
        "\n",
        "history = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BATCH_SIZE,\n",
        "\tverbose=1,\n",
        "\tcallbacks = [sv_callback],\n",
        "\tepochs=50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "[INFO] training head...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/50\n",
            " 298/1018 [=======>......................] - ETA: 2:13:03 - loss: 14.8235 - acc: 0.0554"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:610: UserWarning: The input 370 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1018/1018 [==============================] - 16355s 16s/step - loss: 13.8271 - acc: 0.1099 - val_loss: 11.9769 - val_acc: 0.2097\n",
            "Epoch 2/50\n",
            "   1/1018 [..............................] - ETA: 1:20 - loss: 11.9665 - acc: 0.2188"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKQUhSdQ7-jY"
      },
      "source": [
        "#==============Train2=================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_LREkKv8jHY",
        "outputId": "3e04b9c8-0c02-44c4-dafa-753843a3bbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "#=========================================================================\n",
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model #NetHead1_MODEL_PATH\n",
        "#model = load_model('model.h5')\n",
        "model = load_model(NetHead1_MODEL_PATH)\n",
        "# summarize model.\n",
        "#baseModel.summary()\n",
        "\n",
        "# evaluate the model\n",
        "#score = model.evaluate(X, Y, verbose=0)\n",
        "#print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "#=======================================================================\n",
        "#model=baseModel\n",
        "# reset our data generators\n",
        "#trainGen.reset()\n",
        "#valGen.reset()\n",
        "\n",
        "# now that the head FC layers have been trained/initialized, lets\n",
        "# freeze the final set of CONV layers and make them trainable\n",
        "for layer in model.layers[19:]:\n",
        "\tlayer.trainable = True\n",
        "\n",
        "# loop over the layers in the model and show which ones are trainable\n",
        "# or not\n",
        "for layer in model.layers:\n",
        "\tprint(\"{}: {}\".format(layer, layer.trainable))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7faa9033cb70>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa9033ce10>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d21d0>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7faa902d2320>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d23c8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d2550>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7faa902d26d8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d2780>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d2908>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d2a90>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7faa902d2c18>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d2cc0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d2e48>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa9033cef0>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7faa902d8198>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d8240>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d83c8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7faa902d8550>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7faa902d86d8>: False\n",
            "<keras.layers.core.Flatten object at 0x7faa902d8780>: True\n",
            "<keras.layers.core.Dense object at 0x7faa902d87f0>: True\n",
            "<keras.layers.core.Dropout object at 0x7faa902d8940>: True\n",
            "<keras.layers.core.Dense object at 0x7faa902d8978>: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6XsSE9R8oYE",
        "outputId": "1f42ba45-ad8e-4230-d78e-1763097971d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network for a few epochs (all other layers\n",
        "# are frozen) -- this will allow the new FC layers to start to become\n",
        "# initialized with actual \"learned\" values versus pure random\n",
        "print(\"[INFO] training head...\")\n",
        "import keras\n",
        "modelpath =NetHead_MODEL_PATH #\"/content/drive/My Drive/Data/MDM/vgg16_46labels1.h5\"NetHead_MODEL_PATH\n",
        "sv_callback = keras.callbacks.ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto',period=1)\n",
        "\n",
        "history = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BATCH_SIZE,\n",
        "\tverbose=1,\n",
        "\tcallbacks = [sv_callback],\n",
        "\tepochs=50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training head...\n",
            "Epoch 1/50\n",
            "1018/1018 [==============================] - 13479s 13s/step - loss: 8.2869 - acc: 0.1723 - val_loss: 3.4560 - val_acc: 0.1641\n",
            "Epoch 2/50\n",
            "1018/1018 [==============================] - 652s 640ms/step - loss: 3.4485 - acc: 0.1516 - val_loss: 3.2433 - val_acc: 0.2058\n",
            "Epoch 3/50\n",
            "1018/1018 [==============================] - 649s 638ms/step - loss: 3.3002 - acc: 0.1796 - val_loss: 3.1051 - val_acc: 0.2186\n",
            "Epoch 4/50\n",
            "1018/1018 [==============================] - 649s 637ms/step - loss: 3.1679 - acc: 0.1986 - val_loss: 2.9013 - val_acc: 0.2387\n",
            "Epoch 5/50\n",
            "1018/1018 [==============================] - 626s 615ms/step - loss: 3.0401 - acc: 0.2135 - val_loss: 2.7900 - val_acc: 0.2556\n",
            "Epoch 6/50\n",
            "1018/1018 [==============================] - 621s 610ms/step - loss: 2.9448 - acc: 0.2281 - val_loss: 2.6576 - val_acc: 0.2844\n",
            "Epoch 7/50\n",
            "1018/1018 [==============================] - 610s 599ms/step - loss: 2.8717 - acc: 0.2391 - val_loss: 2.5789 - val_acc: 0.2889\n",
            "Epoch 8/50\n",
            "1018/1018 [==============================] - 606s 595ms/step - loss: 2.8038 - acc: 0.2513 - val_loss: 2.4665 - val_acc: 0.3154\n",
            "Epoch 9/50\n",
            "1018/1018 [==============================] - 608s 597ms/step - loss: 2.7353 - acc: 0.2620 - val_loss: 2.4198 - val_acc: 0.3260\n",
            "Epoch 10/50\n",
            "1018/1018 [==============================] - 609s 598ms/step - loss: 2.6768 - acc: 0.2735 - val_loss: 2.3083 - val_acc: 0.3385\n",
            "Epoch 11/50\n",
            "1018/1018 [==============================] - 602s 592ms/step - loss: 2.6132 - acc: 0.2879 - val_loss: 2.2545 - val_acc: 0.3571\n",
            "Epoch 12/50\n",
            "1018/1018 [==============================] - 605s 594ms/step - loss: 2.5656 - acc: 0.2944 - val_loss: 2.1855 - val_acc: 0.3689\n",
            "Epoch 13/50\n",
            "1018/1018 [==============================] - 595s 585ms/step - loss: 2.5312 - acc: 0.3043 - val_loss: 2.1337 - val_acc: 0.3705\n",
            "Epoch 14/50\n",
            "1018/1018 [==============================] - 595s 585ms/step - loss: 2.4810 - acc: 0.3116 - val_loss: 2.1266 - val_acc: 0.3865\n",
            "Epoch 15/50\n",
            "1018/1018 [==============================] - 599s 589ms/step - loss: 2.4363 - acc: 0.3180 - val_loss: 2.1033 - val_acc: 0.3914\n",
            "Epoch 16/50\n",
            "1018/1018 [==============================] - 604s 593ms/step - loss: 2.4059 - acc: 0.3241 - val_loss: 2.0482 - val_acc: 0.4045\n",
            "Epoch 17/50\n",
            "1018/1018 [==============================] - 604s 593ms/step - loss: 2.3659 - acc: 0.3309 - val_loss: 2.0532 - val_acc: 0.3976\n",
            "Epoch 18/50\n",
            "1018/1018 [==============================] - 606s 595ms/step - loss: 2.3354 - acc: 0.3347 - val_loss: 1.9947 - val_acc: 0.4257\n",
            "Epoch 19/50\n",
            "1018/1018 [==============================] - 613s 602ms/step - loss: 2.3156 - acc: 0.3451 - val_loss: 1.9652 - val_acc: 0.4240\n",
            "Epoch 20/50\n",
            " 312/1018 [========>.....................] - ETA: 6:18 - loss: 2.3086 - acc: 0.3429"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-2C2UxHv5DI"
      },
      "source": [
        "#===================Train3=========="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYueGJ8hv9R1",
        "outputId": "247c115f-c13c-4bf1-d6aa-a39f82150b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "\n",
        "#=========================================================================\n",
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model #NetHead1_MODEL_PATH\n",
        "#model = load_model('model.h5')\n",
        "model = load_model(NetHead19_MODEL_PATH) #INPUT PATH\n",
        "# summarize model.\n",
        "#baseModel.summary()\n",
        "# now that the head FC layers have been trained/initialized, lets\n",
        "# freeze the final set of CONV layers and make them trainable\n",
        "for layer in model.layers[19:]:\n",
        "\tlayer.trainable = True\n",
        "\n",
        "# loop over the layers in the model and show which ones are trainable\n",
        "# or not\n",
        "for layer in model.layers:\n",
        "\tprint(\"{}: {}\".format(layer, layer.trainable))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f69ba59ccf8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69ba59cfd0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69ba5a3208>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69bb80a320>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69bb80a6a0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69bb80a7b8>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69afc6d0b8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6d160>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6d2e8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6d470>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69afc6d5f8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6d6a0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6d828>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6d9b0>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69afc6db38>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6dbe0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6dd68>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69afc6def0>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69afc710b8>: False\n",
            "<keras.layers.core.Flatten object at 0x7f69afc71160>: True\n",
            "<keras.layers.core.Dense object at 0x7f69afc711d0>: True\n",
            "<keras.layers.core.Dropout object at 0x7f69afc71320>: True\n",
            "<keras.layers.core.Dense object at 0x7f69afc71358>: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUO4ftIvwX6U",
        "outputId": "fc60c9db-b2c9-473f-e8ce-bd8f73bf24ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network for a few epochs (all other layers\n",
        "# are frozen) -- this will allow the new FC layers to start to become\n",
        "# initialized with actual \"learned\" values versus pure random\n",
        "print(\"[INFO] training head...\")\n",
        "import keras\n",
        "modelpath =NetHead_MODEL_PATH #OUTPUT PATH\"/content/drive/My Drive/Data/MDM/vgg16_46labels1.h5\"NetHead_MODEL_PATH\n",
        "sv_callback = keras.callbacks.ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto',period=1)\n",
        "\n",
        "history = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BATCH_SIZE,\n",
        "\tverbose=1,\n",
        "\tcallbacks = [sv_callback],\n",
        "\tepochs=50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "[INFO] training head...\n",
            "Epoch 1/50\n",
            "1018/1018 [==============================] - 8506s 8s/step - loss: 2.2375 - acc: 0.3601 - val_loss: 1.8976 - val_acc: 0.4435\n",
            "Epoch 2/50\n",
            "1018/1018 [==============================] - 665s 654ms/step - loss: 2.2157 - acc: 0.3612 - val_loss: 1.8806 - val_acc: 0.4495\n",
            "Epoch 3/50\n",
            "1018/1018 [==============================] - 673s 661ms/step - loss: 2.1847 - acc: 0.3693 - val_loss: 1.8818 - val_acc: 0.4421\n",
            "Epoch 4/50\n",
            "1018/1018 [==============================] - 675s 663ms/step - loss: 2.1628 - acc: 0.3772 - val_loss: 1.8162 - val_acc: 0.4732\n",
            "Epoch 5/50\n",
            "1018/1018 [==============================] - 665s 653ms/step - loss: 2.1452 - acc: 0.3778 - val_loss: 1.8513 - val_acc: 0.4414\n",
            "Epoch 6/50\n",
            "1018/1018 [==============================] - 683s 671ms/step - loss: 2.1225 - acc: 0.3881 - val_loss: 1.7976 - val_acc: 0.4580\n",
            "Epoch 7/50\n",
            "1018/1018 [==============================] - 667s 656ms/step - loss: 2.1208 - acc: 0.3861 - val_loss: 1.7905 - val_acc: 0.4603\n",
            "Epoch 8/50\n",
            "1018/1018 [==============================] - 666s 655ms/step - loss: 2.1093 - acc: 0.3867 - val_loss: 1.7859 - val_acc: 0.4725\n",
            "Epoch 9/50\n",
            "1018/1018 [==============================] - 678s 666ms/step - loss: 2.0770 - acc: 0.3907 - val_loss: 1.7718 - val_acc: 0.4772\n",
            "Epoch 10/50\n",
            "1018/1018 [==============================] - 651s 640ms/step - loss: 2.0593 - acc: 0.4007 - val_loss: 1.7524 - val_acc: 0.4762\n",
            "Epoch 11/50\n",
            "1018/1018 [==============================] - 654s 643ms/step - loss: 2.0442 - acc: 0.4015 - val_loss: 1.7511 - val_acc: 0.4758\n",
            "Epoch 12/50\n",
            "1018/1018 [==============================] - 650s 638ms/step - loss: 2.0292 - acc: 0.4081 - val_loss: 1.7465 - val_acc: 0.4742\n",
            "Epoch 13/50\n",
            "1018/1018 [==============================] - 645s 634ms/step - loss: 2.0024 - acc: 0.4115 - val_loss: 1.7214 - val_acc: 0.4763\n",
            "Epoch 14/50\n",
            "1018/1018 [==============================] - 658s 646ms/step - loss: 1.9994 - acc: 0.4124 - val_loss: 1.7216 - val_acc: 0.4813\n",
            "Epoch 15/50\n",
            "1018/1018 [==============================] - 646s 634ms/step - loss: 1.9877 - acc: 0.4162 - val_loss: 1.6955 - val_acc: 0.4935\n",
            "Epoch 16/50\n",
            "1018/1018 [==============================] - 646s 634ms/step - loss: 1.9711 - acc: 0.4189 - val_loss: 1.6688 - val_acc: 0.5012\n",
            "Epoch 17/50\n",
            "1018/1018 [==============================] - 661s 649ms/step - loss: 1.9651 - acc: 0.4180 - val_loss: 1.6804 - val_acc: 0.4992\n",
            "Epoch 18/50\n",
            "1018/1018 [==============================] - 648s 636ms/step - loss: 1.9563 - acc: 0.4235 - val_loss: 1.6448 - val_acc: 0.5011\n",
            "Epoch 19/50\n",
            "1018/1018 [==============================] - 646s 634ms/step - loss: 1.9421 - acc: 0.4223 - val_loss: 1.6578 - val_acc: 0.4987\n",
            "Epoch 20/50\n",
            "1018/1018 [==============================] - 663s 651ms/step - loss: 1.9336 - acc: 0.4285 - val_loss: 1.6304 - val_acc: 0.5105\n",
            "Epoch 21/50\n",
            " 237/1018 [=====>........................] - ETA: 7:10 - loss: 1.9112 - acc: 0.4276"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1c104d735cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msv_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \tepochs=50)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InDQvuIK9US-"
      },
      "source": [
        "#======================Learn1==================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD2diSuG9WYi"
      },
      "source": [
        "original_model    = InceptionV3()\n",
        "bottleneck_input  = original_model.get_layer(index=0).input\n",
        "bottleneck_output = original_model.get_layer(index=-2).output\n",
        "bottleneck_model  = Model(inputs=bottleneck_input,outputs=bottleneck_output)\n",
        "for layer in bottleneck_model.layers:\n",
        "    layer.trainable = False\n",
        "new_model = Sequential()\n",
        "new_model.add(bottleneck_model)\n",
        "new_model.add(Dense(2, activation=‘softmax’, input_dim=2048))\n",
        "# For a binary classification problem\n",
        "new_model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "one_hot_labels = keras.utils.to_categorical(labels, num_classes=2)\n",
        "new_model.fit(processed_imgs_array,\n",
        "              one_hot_labels,\n",
        "              epochs=2,\n",
        "              batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuT6DxduCnRC"
      },
      "source": [
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z75ODijypgH4"
      },
      "source": [
        "#====================Final training============"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVnwDffHDPTW"
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model #NetHead1_MODEL_PATH\n",
        "#model = load_model('model.h5')\n",
        "model = load_model(NetHead_MODEL_PATH) #INPUT PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXbDjXfazFvt",
        "outputId": "de1ef1c2-c90b-41ef-9152-30d6f8ff9b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# reset our data generators\n",
        "trainGen.reset()\n",
        "valGen.reset()\n",
        "\n",
        "# now that the head FC layers have been trained/initialized, lets\n",
        "# unfreeze the final set of CONV layers and make them trainable\n",
        "\"\"\"\n",
        "for layer in baseModel.layers[15:]:\n",
        "\tlayer.trainable = True\n",
        "\"\"\"\n",
        "for layer in model.layers[15:]:\n",
        "\tlayer.trainable = True\n",
        "# loop over the layers in the model and show which ones are trainable\n",
        "# or not\n",
        "for layer in model.layers:\n",
        "\tprint(\"{}: {}\".format(layer, layer.trainable))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f69b15407f0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b14e39b0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b14f3710>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69b14f3ac8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b14f3b38>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b14f3ba8>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69b14f3d68>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b14f3cf8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b14f3780>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b1540a90>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69b1540a20>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b1540b38>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b1540c88>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b1540e10>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69b1540f98>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b1559080>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b1559208>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f69b1559390>: True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f69b1559518>: True\n",
            "<keras.layers.core.Flatten object at 0x7f69b15595c0>: True\n",
            "<keras.layers.core.Dense object at 0x7f69b1559630>: True\n",
            "<keras.layers.core.Dropout object at 0x7f69b1559780>: True\n",
            "<keras.layers.core.Dense object at 0x7f69b15597b8>: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd5wnw5t1jXu",
        "outputId": "e1845b5e-dd91-4e01-c609-5a65f324307e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# for the changes to the model to take affect we need to recompile\n",
        "# the model, this time using SGD with a *very* small learning rate\n",
        "print(\"[INFO] re-compiling model...\")\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the model again, this time fine-tuning *both* the final set\n",
        "# of CONV layers along with our set of FC layers\n",
        "\n",
        "modelpath =NetComplete_MODEL_PATH #OUTPUT \"/content/drive/My Drive/Data/MDM/vgg16_46labels1.h5\"\n",
        "sv_callback = keras.callbacks.ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto',period=1)\n",
        "\n",
        "history = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BATCH_SIZE,\n",
        "\tverbose=1,\n",
        "\tcallbacks = [sv_callback],\n",
        "\tepochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] re-compiling model...\n",
            "Epoch 1/50\n",
            "1018/1018 [==============================] - 683s 671ms/step - loss: 1.8775 - acc: 0.4437 - val_loss: 1.5606 - val_acc: 0.5367\n",
            "Epoch 2/50\n",
            "1018/1018 [==============================] - 672s 660ms/step - loss: 1.7137 - acc: 0.4805 - val_loss: 1.4394 - val_acc: 0.5584\n",
            "Epoch 3/50\n",
            "1018/1018 [==============================] - 675s 663ms/step - loss: 1.6035 - acc: 0.5061 - val_loss: 1.3604 - val_acc: 0.5782\n",
            "Epoch 4/50\n",
            "1018/1018 [==============================] - 693s 681ms/step - loss: 1.5033 - acc: 0.5356 - val_loss: 1.3208 - val_acc: 0.5902\n",
            "Epoch 5/50\n",
            "1018/1018 [==============================] - 671s 659ms/step - loss: 1.4134 - acc: 0.5603 - val_loss: 1.2042 - val_acc: 0.6181\n",
            "Epoch 6/50\n",
            "1018/1018 [==============================] - 680s 668ms/step - loss: 1.3362 - acc: 0.5777 - val_loss: 1.2143 - val_acc: 0.6262\n",
            "Epoch 7/50\n",
            "1018/1018 [==============================] - 674s 663ms/step - loss: 1.2723 - acc: 0.5968 - val_loss: 1.1507 - val_acc: 0.6405\n",
            "Epoch 8/50\n",
            "1018/1018 [==============================] - 669s 657ms/step - loss: 1.2077 - acc: 0.6168 - val_loss: 1.1428 - val_acc: 0.6507\n",
            "Epoch 9/50\n",
            "1018/1018 [==============================] - 685s 673ms/step - loss: 1.1298 - acc: 0.6423 - val_loss: 1.0894 - val_acc: 0.6677\n",
            "Epoch 10/50\n",
            "1018/1018 [==============================] - 671s 659ms/step - loss: 1.0887 - acc: 0.6554 - val_loss: 1.1255 - val_acc: 0.6641\n",
            "Epoch 11/50\n",
            "1018/1018 [==============================] - 668s 656ms/step - loss: 1.0281 - acc: 0.6740 - val_loss: 1.0548 - val_acc: 0.6850\n",
            "Epoch 12/50\n",
            "1018/1018 [==============================] - 686s 674ms/step - loss: 0.9748 - acc: 0.6904 - val_loss: 1.0202 - val_acc: 0.6955\n",
            "Epoch 13/50\n",
            "1018/1018 [==============================] - 672s 660ms/step - loss: 0.9262 - acc: 0.7032 - val_loss: 0.9573 - val_acc: 0.7115\n",
            "Epoch 14/50\n",
            "1018/1018 [==============================] - 681s 669ms/step - loss: 0.8846 - acc: 0.7175 - val_loss: 0.9744 - val_acc: 0.7089\n",
            "Epoch 15/50\n",
            "1018/1018 [==============================] - 675s 663ms/step - loss: 0.8300 - acc: 0.7353 - val_loss: 0.9515 - val_acc: 0.7186\n",
            "Epoch 16/50\n",
            "1018/1018 [==============================] - 670s 658ms/step - loss: 0.8136 - acc: 0.7417 - val_loss: 0.9314 - val_acc: 0.7237\n",
            "Epoch 17/50\n",
            "1018/1018 [==============================] - 688s 675ms/step - loss: 0.7566 - acc: 0.7560 - val_loss: 0.8946 - val_acc: 0.7396\n",
            "Epoch 18/50\n",
            "1018/1018 [==============================] - 670s 658ms/step - loss: 0.7282 - acc: 0.7644 - val_loss: 0.8391 - val_acc: 0.7551\n",
            "Epoch 19/50\n",
            "1018/1018 [==============================] - 670s 658ms/step - loss: 0.7033 - acc: 0.7761 - val_loss: 0.9097 - val_acc: 0.7426\n",
            "Epoch 20/50\n",
            " 569/1018 [===============>..............] - ETA: 4:33 - loss: 0.6686 - acc: 0.7858"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKwYVvA7BzRG"
      },
      "source": [
        "#=============Final Training2==============="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "graX1kaNB4IY",
        "outputId": "477cbae7-0d7a-49c8-9849-5abbb4b5cb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model #NetHead1_MODEL_PATH\n",
        "#model = load_model('model.h5')\n",
        "model = load_model(NetComplete19_MODEL_PATH) #INPUT PATH\n",
        "for layer in model.layers:\n",
        "\tprint(\"{}: {}\".format(layer, layer.trainable))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "<keras.engine.input_layer.InputLayer object at 0x7fadce73f048>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce73fba8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce73f3c8>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fadce0b6080>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b6128>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b62b0>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fadce0b6438>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b64e0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b6668>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b67f0>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fadce0b6978>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b6a20>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b6ba8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b6d30>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fadce0b6eb8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0b6f60>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0ba128>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fadce0ba2b0>: True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fadce0ba438>: True\n",
            "<keras.layers.core.Flatten object at 0x7fadce0ba4e0>: True\n",
            "<keras.layers.core.Dense object at 0x7fadce0ba550>: True\n",
            "<keras.layers.core.Dropout object at 0x7fadce0ba6a0>: True\n",
            "<keras.layers.core.Dense object at 0x7fadce0ba6d8>: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c78OzIWCBbL",
        "outputId": "11ea4ae6-d39b-4f56-f768-a4297a556e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# for the changes to the model to take affect we need to recompile\n",
        "# the model, this time using SGD with a *very* small learning rate\n",
        "print(\"[INFO] re-compiling model...\")\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the model again, this time fine-tuning *both* the final set\n",
        "# of CONV layers along with our set of FC layers\n",
        "\n",
        "modelpath =NetComplete_MODEL_PATH #OUTPUT \"/content/drive/My Drive/Data/MDM/vgg16_46labels1.h5\"\n",
        "sv_callback = keras.callbacks.ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto',period=1)\n",
        "\n",
        "history = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BATCH_SIZE,\n",
        "\tverbose=1,\n",
        "\tcallbacks = [sv_callback],\n",
        "\tepochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] re-compiling model...\n",
            "Epoch 1/50\n",
            "1018/1018 [==============================] - 8155s 8s/step - loss: 0.6914 - acc: 0.7781 - val_loss: 0.8136 - val_acc: 0.7577\n",
            "Epoch 2/50\n",
            "1018/1018 [==============================] - 597s 587ms/step - loss: 0.6635 - acc: 0.7864 - val_loss: 0.8139 - val_acc: 0.7636\n",
            "Epoch 3/50\n",
            "1018/1018 [==============================] - 592s 581ms/step - loss: 0.6372 - acc: 0.7976 - val_loss: 0.8177 - val_acc: 0.7616\n",
            "Epoch 4/50\n",
            "1018/1018 [==============================] - 588s 577ms/step - loss: 0.6041 - acc: 0.8048 - val_loss: 0.8064 - val_acc: 0.7686\n",
            "Epoch 5/50\n",
            "1018/1018 [==============================] - 585s 575ms/step - loss: 0.5751 - acc: 0.8160 - val_loss: 0.8473 - val_acc: 0.7602\n",
            "Epoch 6/50\n",
            "1018/1018 [==============================] - 591s 580ms/step - loss: 0.5463 - acc: 0.8223 - val_loss: 0.7423 - val_acc: 0.7879\n",
            "Epoch 7/50\n",
            "1018/1018 [==============================] - 579s 569ms/step - loss: 0.5225 - acc: 0.8326 - val_loss: 0.7726 - val_acc: 0.7826\n",
            "Epoch 8/50\n",
            "1018/1018 [==============================] - 577s 567ms/step - loss: 0.5027 - acc: 0.8371 - val_loss: 0.7217 - val_acc: 0.7940\n",
            "Epoch 9/50\n",
            "1018/1018 [==============================] - 586s 576ms/step - loss: 0.4708 - acc: 0.8475 - val_loss: 0.7124 - val_acc: 0.7989\n",
            "Epoch 10/50\n",
            "1018/1018 [==============================] - 583s 573ms/step - loss: 0.4594 - acc: 0.8502 - val_loss: 0.6723 - val_acc: 0.8132\n",
            "Epoch 11/50\n",
            "1018/1018 [==============================] - 575s 565ms/step - loss: 0.4376 - acc: 0.8584 - val_loss: 0.6861 - val_acc: 0.7954\n",
            "Epoch 12/50\n",
            "1018/1018 [==============================] - 580s 570ms/step - loss: 0.4119 - acc: 0.8683 - val_loss: 0.7043 - val_acc: 0.8035\n",
            "Epoch 13/50\n",
            "1018/1018 [==============================] - 579s 569ms/step - loss: 0.4028 - acc: 0.8699 - val_loss: 0.6437 - val_acc: 0.8184\n",
            "Epoch 14/50\n",
            "1018/1018 [==============================] - 576s 566ms/step - loss: 0.3853 - acc: 0.8754 - val_loss: 0.6468 - val_acc: 0.8188\n",
            "Epoch 15/50\n",
            "1018/1018 [==============================] - 579s 569ms/step - loss: 0.3628 - acc: 0.8836 - val_loss: 0.6638 - val_acc: 0.8252\n",
            "Epoch 16/50\n",
            "1018/1018 [==============================] - 580s 570ms/step - loss: 0.3514 - acc: 0.8846 - val_loss: 0.6937 - val_acc: 0.8219\n",
            "Epoch 17/50\n",
            "1018/1018 [==============================] - 573s 563ms/step - loss: 0.3332 - acc: 0.8924 - val_loss: 0.6607 - val_acc: 0.8190\n",
            "Epoch 18/50\n",
            "1018/1018 [==============================] - 576s 566ms/step - loss: 0.3196 - acc: 0.8965 - val_loss: 0.5771 - val_acc: 0.8406\n",
            "Epoch 19/50\n",
            "1018/1018 [==============================] - 581s 570ms/step - loss: 0.3139 - acc: 0.8998 - val_loss: 0.5809 - val_acc: 0.8394\n",
            "Epoch 20/50\n",
            "1018/1018 [==============================] - 571s 561ms/step - loss: 0.2937 - acc: 0.9055 - val_loss: 0.5854 - val_acc: 0.8441\n",
            "Epoch 21/50\n",
            "1018/1018 [==============================] - 576s 566ms/step - loss: 0.2889 - acc: 0.9070 - val_loss: 0.5441 - val_acc: 0.8503\n",
            "Epoch 22/50\n",
            "1018/1018 [==============================] - 580s 570ms/step - loss: 0.2773 - acc: 0.9128 - val_loss: 0.6233 - val_acc: 0.8339\n",
            "Epoch 23/50\n",
            "1018/1018 [==============================] - 572s 562ms/step - loss: 0.2744 - acc: 0.9119 - val_loss: 0.5106 - val_acc: 0.8579\n",
            "Epoch 24/50\n",
            "1018/1018 [==============================] - 570s 560ms/step - loss: 0.2539 - acc: 0.9177 - val_loss: 0.4802 - val_acc: 0.8687\n",
            "Epoch 25/50\n",
            "1018/1018 [==============================] - 575s 565ms/step - loss: 0.2504 - acc: 0.9194 - val_loss: 0.4804 - val_acc: 0.8649\n",
            "Epoch 26/50\n",
            "1018/1018 [==============================] - 569s 559ms/step - loss: 0.2541 - acc: 0.9202 - val_loss: 0.6228 - val_acc: 0.8421\n",
            "Epoch 27/50\n",
            "1018/1018 [==============================] - 569s 559ms/step - loss: 0.2314 - acc: 0.9266 - val_loss: 0.4677 - val_acc: 0.8705\n",
            "Epoch 28/50\n",
            "1018/1018 [==============================] - 571s 561ms/step - loss: 0.2213 - acc: 0.9288 - val_loss: 0.5104 - val_acc: 0.8628\n",
            "Epoch 29/50\n",
            "1018/1018 [==============================] - 569s 559ms/step - loss: 0.2102 - acc: 0.9315 - val_loss: 0.5501 - val_acc: 0.8599\n",
            "Epoch 30/50\n",
            "1018/1018 [==============================] - 568s 558ms/step - loss: 0.2063 - acc: 0.9320 - val_loss: 0.4450 - val_acc: 0.8767\n",
            "Epoch 31/50\n",
            "1018/1018 [==============================] - 572s 562ms/step - loss: 0.1997 - acc: 0.9362 - val_loss: 0.4753 - val_acc: 0.8794\n",
            "Epoch 32/50\n",
            "1018/1018 [==============================] - 570s 559ms/step - loss: 0.2003 - acc: 0.9357 - val_loss: 0.5392 - val_acc: 0.8610\n",
            "Epoch 33/50\n",
            "1018/1018 [==============================] - 572s 562ms/step - loss: 0.1875 - acc: 0.9399 - val_loss: 0.4516 - val_acc: 0.8800\n",
            "Epoch 34/50\n",
            "1018/1018 [==============================] - 575s 565ms/step - loss: 0.1741 - acc: 0.9435 - val_loss: 0.4564 - val_acc: 0.8814\n",
            "Epoch 35/50\n",
            "1018/1018 [==============================] - 581s 571ms/step - loss: 0.1764 - acc: 0.9451 - val_loss: 0.4968 - val_acc: 0.8735\n",
            "Epoch 36/50\n",
            "1018/1018 [==============================] - 581s 570ms/step - loss: 0.1692 - acc: 0.9449 - val_loss: 0.3816 - val_acc: 0.8966\n",
            "Epoch 37/50\n",
            "1018/1018 [==============================] - 580s 569ms/step - loss: 0.1622 - acc: 0.9468 - val_loss: 0.4406 - val_acc: 0.8912\n",
            "Epoch 38/50\n",
            "1018/1018 [==============================] - 578s 568ms/step - loss: 0.1590 - acc: 0.9486 - val_loss: 0.4565 - val_acc: 0.8865\n",
            "Epoch 39/50\n",
            "1018/1018 [==============================] - 581s 570ms/step - loss: 0.1554 - acc: 0.9497 - val_loss: 0.4462 - val_acc: 0.8859\n",
            "Epoch 40/50\n",
            "1018/1018 [==============================] - 580s 569ms/step - loss: 0.1524 - acc: 0.9507 - val_loss: 0.4309 - val_acc: 0.8941\n",
            "Epoch 41/50\n",
            "1018/1018 [==============================] - 580s 570ms/step - loss: 0.1481 - acc: 0.9527 - val_loss: 0.4278 - val_acc: 0.8919\n",
            "Epoch 42/50\n",
            "1018/1018 [==============================] - 574s 564ms/step - loss: 0.1388 - acc: 0.9550 - val_loss: 0.4086 - val_acc: 0.8972\n",
            "Epoch 43/50\n",
            "1018/1018 [==============================] - 576s 565ms/step - loss: 0.1369 - acc: 0.9562 - val_loss: 0.4809 - val_acc: 0.8897\n",
            "Epoch 44/50\n",
            "1018/1018 [==============================] - 576s 566ms/step - loss: 0.1344 - acc: 0.9569 - val_loss: 0.4432 - val_acc: 0.8876\n",
            "Epoch 45/50\n",
            "1018/1018 [==============================] - 569s 559ms/step - loss: 0.1292 - acc: 0.9594 - val_loss: 0.4269 - val_acc: 0.8972\n",
            "Epoch 46/50\n",
            "1018/1018 [==============================] - 568s 558ms/step - loss: 0.1234 - acc: 0.9605 - val_loss: 0.4097 - val_acc: 0.9024\n",
            "Epoch 47/50\n",
            "1018/1018 [==============================] - 570s 560ms/step - loss: 0.1218 - acc: 0.9616 - val_loss: 0.3718 - val_acc: 0.9068\n",
            "Epoch 48/50\n",
            "1018/1018 [==============================] - 570s 560ms/step - loss: 0.1181 - acc: 0.9624 - val_loss: 0.3315 - val_acc: 0.9136\n",
            "Epoch 49/50\n",
            "1018/1018 [==============================] - 571s 561ms/step - loss: 0.1170 - acc: 0.9623 - val_loss: 0.4355 - val_acc: 0.8986\n",
            "Epoch 50/50\n",
            " 321/1018 [========>.....................] - ETA: 5:48 - loss: 0.1193 - acc: 0.9630"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRae-za_9etV"
      },
      "source": [
        "#============Final train3=========="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuPvUlP19jw9",
        "outputId": "3ac16836-b6af-47e9-e94f-96dc902c85cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "# load model #NetHead1_MODEL_PATH\n",
        "#model = load_model('model.h5')\n",
        "#NetComplete49_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetComplete49.h5\"\n",
        "NetComplete49_6_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetComplete49_6.h5\"\n",
        "model = load_model(NetComplete49_6_MODEL_PATH) #INPUT PATH\n",
        "for layer in model.layers:\n",
        "\tprint(\"{}: {}\".format(layer, layer.trainable))\n",
        " # for the changes to the model to take affect we need to recompile\n",
        "# the model, this time using SGD with a *very* small learning rate\n",
        "print(\"[INFO] re-compiling model...\")\n",
        "opt = SGD(lr=1e-4, momentum=0.9)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the model again, this time fine-tuning *both* the final set\n",
        "# of CONV layers along with our set of FC layers\n",
        "\n",
        "modelpath =NetComplete_MODEL_PATH #OUTPUT \"/content/drive/My Drive/Data/MDM/vgg16_46labels1.h5\"\n",
        "sv_callback = keras.callbacks.ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto',period=1)\n",
        "\n",
        "history = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BATCH_SIZE,\n",
        "\tverbose=1,\n",
        "\tcallbacks = [sv_callback],\n",
        "\tepochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "<keras.engine.input_layer.InputLayer object at 0x7fcfbd0ade10>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbd0adba8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbd7208>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fcfbfbd74a8>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbd7550>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbd76d8>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fcfbfbd7860>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbd7908>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbd7a90>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbd7c18>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fcfbfbd7da0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbd7e48>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbd0adfd0>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbe5198>: False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fcfbfbe5320>: False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbe53c8>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbe5550>: True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fcfbfbe56d8>: True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fcfbfbe5860>: True\n",
            "<keras.layers.core.Flatten object at 0x7fcfbfbe5908>: True\n",
            "<keras.layers.core.Dense object at 0x7fcfbfbe5978>: True\n",
            "<keras.layers.core.Dropout object at 0x7fcfbfbe5ac8>: True\n",
            "<keras.layers.core.Dense object at 0x7fcfbfbe5b00>: True\n",
            "[INFO] re-compiling model...\n",
            "Epoch 1/50\n",
            "1018/1018 [==============================] - 21088s 21s/step - loss: 0.1200 - acc: 0.9616 - val_loss: 0.3791 - val_acc: 0.9067\n",
            "Epoch 2/50\n",
            "1018/1018 [==============================] - 697s 685ms/step - loss: 0.1130 - acc: 0.9641 - val_loss: 0.4699 - val_acc: 0.8951\n",
            "Epoch 3/50\n",
            "1018/1018 [==============================] - 703s 691ms/step - loss: 0.1174 - acc: 0.9636 - val_loss: 0.3883 - val_acc: 0.9054\n",
            "Epoch 4/50\n",
            "1018/1018 [==============================] - 707s 695ms/step - loss: 0.1069 - acc: 0.9666 - val_loss: 0.4068 - val_acc: 0.9023\n",
            "Epoch 5/50\n",
            "1018/1018 [==============================] - 699s 687ms/step - loss: 0.1088 - acc: 0.9658 - val_loss: 0.3212 - val_acc: 0.9213\n",
            "Epoch 6/50\n",
            "1018/1018 [==============================] - 707s 694ms/step - loss: 0.1016 - acc: 0.9685 - val_loss: 0.3503 - val_acc: 0.9168\n",
            "Epoch 7/50\n",
            "1018/1018 [==============================] - 700s 688ms/step - loss: 0.0990 - acc: 0.9676 - val_loss: 0.3186 - val_acc: 0.9190\n",
            "Epoch 8/50\n",
            "1018/1018 [==============================] - 701s 688ms/step - loss: 0.1069 - acc: 0.9670 - val_loss: 0.3501 - val_acc: 0.9137\n",
            "Epoch 9/50\n",
            "1018/1018 [==============================] - 717s 704ms/step - loss: 0.1028 - acc: 0.9668 - val_loss: 0.3962 - val_acc: 0.9052\n",
            "Epoch 10/50\n",
            "1018/1018 [==============================] - 705s 692ms/step - loss: 0.1020 - acc: 0.9674 - val_loss: 0.3137 - val_acc: 0.9195\n",
            "Epoch 11/50\n",
            "1018/1018 [==============================] - 661s 649ms/step - loss: 0.0947 - acc: 0.9699 - val_loss: 0.3563 - val_acc: 0.9158\n",
            "Epoch 12/50\n",
            "1018/1018 [==============================] - 659s 647ms/step - loss: 0.0886 - acc: 0.9720 - val_loss: 0.3569 - val_acc: 0.9161\n",
            "Epoch 13/50\n",
            "1018/1018 [==============================] - 651s 640ms/step - loss: 0.0883 - acc: 0.9720 - val_loss: 0.3272 - val_acc: 0.9233\n",
            "Epoch 14/50\n",
            "1018/1018 [==============================] - 660s 648ms/step - loss: 0.0901 - acc: 0.9720 - val_loss: 0.3814 - val_acc: 0.9126\n",
            "Epoch 15/50\n",
            "1018/1018 [==============================] - 661s 650ms/step - loss: 0.0839 - acc: 0.9741 - val_loss: 0.3415 - val_acc: 0.9195\n",
            "Epoch 16/50\n",
            "1018/1018 [==============================] - 680s 668ms/step - loss: 0.0853 - acc: 0.9729 - val_loss: 0.3407 - val_acc: 0.9213\n",
            "Epoch 17/50\n",
            "1018/1018 [==============================] - 683s 671ms/step - loss: 0.0804 - acc: 0.9731 - val_loss: 0.3056 - val_acc: 0.9279\n",
            "Epoch 18/50\n",
            " 225/1018 [=====>........................] - ETA: 7:39 - loss: 0.0612 - acc: 0.9774"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFg1Z7xV9ly_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHZJawigrGEr"
      },
      "source": [
        "#==================Graph Plotting Final Model================"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nY8LIjKLIo_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9WxMn2Inaqg"
      },
      "source": [
        "# reset the testing generator and then use our trained model to\n",
        "# make predictions on the data\n",
        "print(\"[INFO] evaluating after fine-tuning network...\")\n",
        "testGen.reset()\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(totalTest // config.BATCH_SIZE) + 1)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(classification_report(testGen.classes, predIdxs,\n",
        "\ttarget_names=testGen.class_indices.keys()))\n",
        "plot_training(H, 20, config.UNFROZEN_PLOT_PATH)\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5IVFTwy1nkV"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnhztZrEoxpj"
      },
      "source": [
        "#=============Predict=============="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJtan4wwo0Qb"
      },
      "source": [
        "# USAGE\n",
        "# python predict.py --image dataset/evaluation/Egg/3_137.jpg\n",
        "\n",
        "# import the necessary packages\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import imutils\n",
        "import cv2\n",
        "CLASSES=['Aloo Baingan','Aloo Gajar Mutter','Aloo Gobhi','Aloo Methi','Aloo Mutter','Aloo Nutri','Aloo Sabzi','Aloo Shimla Mirch','Amrood','Apple','Banana','Besan Kadi','Bhindi','Boiled Egg','Boiled Plain Rice','Boondi Raita','Chai','Chana Dal','Chana Dal Chawal','Chana Lauki Dal','Chole','Chole Chawal','Dahi','Dal Palak','Kadi Chawal','Kale Chane','Kheera Raita','Kheera Salad','Khichdi Moong Dal','Khichi Urad Dal','Lassi','Lauki','Lobia Dal','Masoor Dal','Milk','Mooli Ki Sabzi','Moong Masoor Ki Dal','Orange','Patta Gobi','Rajma','Rajma Chawal','Ramdana','Roti','Saag','Urad Ki Dal','Water']\n",
        "NetComplete_MODEL_PATH=\"/content/drive/My Drive/IMG_Classification/Fine_tune_keras/VGG16/output/VGG16_NetComplete.h5\"\n",
        "\n",
        "MODEL_PATH=NetComplete_MODEL_PATH\n",
        "# load the trained model from disk\n",
        "print(\"[INFO] loading model...\")\n",
        "model = load_model(MODEL_PATH)\n",
        "\n",
        "img_PATH=\"/content/drive/My Drive/Data/MDM/test/Aloo Baingan/24 (448).jpg\"\n",
        "# load the input image and then clone it so we can draw on it later\n",
        "image = cv2.imread(img_PATH)\n",
        "output = image.copy()\n",
        "output = imutils.resize(output, width=400)\n",
        "\n",
        "# our model was trained on RGB ordered images but OpenCV represents\n",
        "# images in BGR order, so swap the channels, and then resize to\n",
        "# 224x224 (the input dimensions for VGG16)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = cv2.resize(image, (224, 224))\n",
        "\n",
        "# convert the image to a floating point data type and perform mean\n",
        "# subtraction\n",
        "image = image.astype(\"float32\")\n",
        "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
        "image -= mean\n",
        "\n",
        "# pass the image through the network to obtain our predictions\n",
        "preds = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "i = np.argmax(preds)\n",
        "label = CLASSES[i]\n",
        "\n",
        "# draw the prediction on the output image\n",
        "text = \"{}: {:.2f}%\".format(label, preds[i] * 100)\n",
        "cv2.putText(output, text, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "\t(0, 255, 0), 2)\n",
        "\n",
        "# show the output image\n",
        "cv2.imshow(\"Output\", output)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as8GILS7onLG"
      },
      "source": []
    }
  ]
}